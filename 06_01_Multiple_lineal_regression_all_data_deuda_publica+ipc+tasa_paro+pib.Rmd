---
title: "06_Multiple_lineal_regresion_deuda_publica+ipc+tasa_paro+pib"
output: html_document
---

setwd("~/Documents/KSCHOOL_ESTADISTICA/TFM")
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Primer modelo
Regresión lineal utilizando como predictores únicamente los datos propios del Índice IBEX 35. Este índice integra las cotizaciones de las 35 empresas más importantes de España. Es un índice ponderado según la capitalización bursatil de las 35 empresas que lo componen; es decir, las empresas que tienen una mayor capitalización tiene más peso en el índice.
El dataset con el que trabajaremos dispone de las siguientes variables:
- fecha, día de la muestra
- último, valor de cierre del índice expresado en puntos para ese día (unidad puntos)
- apertura, valor de apertura del índice expresado en puntos para ese día
- máximo, valor máximo alcanzado del índice expresado en puntos para ese día
- mínimo, valor mínimo alcanzado del índice expresado en puntos para ese día
- volumen, número de operaciones de compraventa cerradas para ese día (unidad millones)
- variación, variación del valor del índice con respecto al día anterior (unidad %)
- deuda_publica, conjunto de deudas que mantiene el Estado español frente a los particulares que pueden ser españoles o de otro país
- ipc, indicador que mide la variación de los precios de una cesta de bienes y servicios en un lugar concreto durante un determinado periodo de tiempo
- tasa_paro, mide el nivel de desocupación en relación con la población activa
- pib, suma de todos los bienes y servicios finales que produce un país o una economía, elaborados dentro del territorio nacional tanto por empresas nacionales como extranjeras, y que se registran en un periodo determinado
La variable a predecir:  
- el valor último o de cierre

En esta primera prueba vamos a utilizar el dataset completo con datos desde el 09-09-1991.

# Carga de las librerias y datos
```{r, warning=FALSE, message=FALSE}
library(dplyr)
library(leaps)
library(caret)

data <- read.csv('./dataset/IBEX35/final_historic_data_IBEX35_with_metrics_toR_all.csv', sep = ',', header = T, fileEncoding = 'utf-8')
```

# Análisis exploratorio de los datos y relación entre variables

Visualizamos una pequeña muestra de los datos para observar su tipología:
```{r, warning=FALSE, message=FALSE}
glimpse(data)
```

Obtenemos más información de los datos de las variables para conocer información como el valor mínimo, máximo, media, mediana, primer y tercer cuartil:
```{r, warning=FALSE, message=FALSE}
summary(data)
```

Realizamos un diagrama de dispersión para analizar los datos con respecto a las variables y ver la dispersión de los mismos:
```{r pressure, echo=FALSE}
pairs(data, col = 'skyblue')
```

Y pintamos la matríz de correlación:
```{r}
cor(data)
```
Esta información es crítica a la hora de identificar cuáles pueden ser los mejores predictores para el modelo, qué variables presentan relaciones de tipo no lineal y para identificar colinialidad entre predictores.
De este análisis se pueden extraer las siguientes conclusiones:
- Las variables que tienen una mayor relación lineal con ultimo son: apertura (r=0.999400591), maximo (r=0.999693914) y minimo (r=0.999732987)
- Los predictores apertura, maximo y minimo estan altamente correlacionados (r=0.99) por lo que no se van a utilizar
- La variable variación como depende directamente de la variable a predecir tampoco se va a incorporar
- Las variables que presenta bastante relación lineal con ultimo son: deuda_publica (r=0.429966202), ipc (r=0.404185096), tasa_paro (r=0.418799904) y en menor medida pib (r=0.181604932)

# Selección de los predictores y ajuste de un modelo lineal múltiple

Creamos training y test, 80% y 20% del dataset
```{r}
set.seed(23)
split <- 0.8
dataIndex <- createDataPartition(data$ultimo, p=split, list=FALSE)
head(dataIndex)
```

```{r}
data_training <- data[dataIndex,]
data_test <- data[-dataIndex,]
```

Para la selección de los predictores vamos a utilizar la técnica "Best Subset Selection" que consiste en evaluar todos los posibles modelos que se pueden crear por combinación de los predictores disponibles.
```{r}
bss.model <- regsubsets(ultimo ~ deuda_publica + ipc + tasa_paro + pib, data = data_training)
summary(bss.model)
```


Ahora vamos a evaluar distintos estadísticos para ver cuál es el mejor modelo:
- Adj.R2: Adjusted r-squared, se corresponde al cuadrado de la correlación entre la variable respuesta y el modelo lineal ajustado. En este caso cuanto mayor es el R2 ajustado menor su test error. Una vez las variables más importantes han sido incluidas en el modelo, la adición de variables adicionales con poca relación con la variable respuesta solo añadirá ruido y una pequeña reducción en el RSS; es decir, penaliza la inclusión de variables innecesarias.
- RSS: Residual sum of squares for each model. RSS siempre disminuye conforme más predictores se incluyan en el modelo.
- MSE: Test mean squared error, que equivale al test Residual Sum of Squares dividido entre el número de observaciones.
- CP: Cp de Mallow, es un estimador del test MSE de un modelo ajustado por mínimos cuadrados con d predictores donde σ2 es la estimación de la varianza del error asociado a cada observación. Este estadístico añade una penalización de 2dσ2 al training RSS, dado que este tiende a subestimar el test error. La penalización aumenta conforme aumenta el número de predictores. Este estadístico tiende a ser bajo para modelos con un test error bajo, por lo que, el mejor modelo corresponde a aquel con menor Cp.
- BIC: Criterio de Información Bayesiana, el estadístico BIC aumenta la penalidad en modelos con muchas variables. Valores pequeños de BIC corresponde a un test error bajo, por lo que el mejor modelo será aquel con menor BIC.
```{r}
res.sum <- summary(bss.model)
#MSE <- mean(lm_fit_ultimo_all$residuals^2)

data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  RSS = which.min(res.sum$rss),
  MSE = which.min(res.sum$rss/length(data)),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
```

A continuación vamos a plotear como quedarían el estadístico en cada modelo:
```{r}
plot(res.sum$adjr2, type = 'l')
plot(res.sum$rss, type = 'l')
plot(res.sum$rss/length(data), type = 'l')
plot(res.sum$cp, type = 'l')
plot(res.sum$bic, type = 'l')
```
Por el criterio "del codo" en todos los estadísticos tiene sentido tomar 3 variables.


En una primera prueba se van a considerar utilizar todos las variables ya que minimizan el MSE:
```{r}
lm_fit_ultimo_all <- lm(ultimo ~ deuda_publica + ipc + tasa_paro + pib, data = data_training)
summary(lm_fit_ultimo_all)
```
Según observamos en los resultados el coeficiente obtenido para deuda_publica, ipc, tasa_paro y pib son estadísticamente significativos (los valores obtenidos de p-valor son significativamente bajos por lo que podemos rechazar la hipótesis nula) por lo que podemos establecer que existe relación entre los predictores y la respuesta.

El valor Multiple R-squared (R2) indica que el modelo calculado explica el 38,74% de la variablidad presente en la variable respuesta (ultimo) a su promedio es explicado por el modelo de regresión ajustado. Podemos concluir que el modelo lineal es adecuado para describir la relación que existe entre esas variables independientes (apertura y vol). El p-value del modelo es significativo (2.2e-16) por lo que se puede aceptar que el modelo no es por azar.

Vamos a calcular el test MSE (mean squared error) del modelo:
```{r}
mse_lm_fit_ultimo_all <- mean(lm_fit_ultimo_all$residuals^2)
mse_lm_fit_ultimo_all

# Otra forma de calcularlo:
#mse_training_predict_lm_fit_ultimo_all <- mean((data_training$ultimo - lm_fit_ultimo_all$fitted.values)^2)
#mse_training_predict_lm_fit_ultimo_all
```

El modelo que se obtiene es:
$$
ultimo = 5.878e\+03 + 2.690e\-03 \cdot deuda_publica + 6.678e\+02  \cdot ipc + 2.610e\+01  \cdot tasa_paro + 9.704e\+02  \cdot pib
$$
El modelo explica que a mayor valor de ultimo se produce un incremento en el resto de las variables.


A continuación vamos a mostrar los pesos de los predictores para ver las variables más influyentes:
```{r}
coef <- lm_fit_ultimo_all$coefficients
abs(coef/min(abs(coef)))
```
Los coeficientes más importante son la deuda_publica, pib e ipc, así que son los que más influyen en el valor de cierre. La tasa de paro es lo menos importante.

Obtenemos los intervalos de confianza del 95% y podemos indicar que las pendientes (coefficients) obtenidas para las distintas variables se encuentran entre los rangos obtenidos.
```{r}
confint(lm_fit_ultimo_all, level = 0.95)
```


Vamos a representar de forma gráfica los valores reales frente a predichos y residuos frente a valores reales:
```{r, fig.align='center'}
par(mfrow = c(1,2))

plot(data_training$ultimo, lm_fit_ultimo_all$fitted.values, type = 'p', col = 'skyblue', xlab = 'ultimo', ylab = 'Predicted ultimo')
plot(data_training$ultimo, lm_fit_ultimo_all$residuals, type = 'p', col = 'red', xlab = 'ultimo', ylab = 'Residuals')
```

A continuación vamos a plotear la distribución de los residuos:
```{r, fig.align='center'}
data_lm_all <- data_training
data_lm_all$predict <- lm_fit_ultimo_all$fitted.values
data_lm_all$residuos <- lm_fit_ultimo_all$residuals
head(data_lm_all)
```


```{r, fig.align='center'}
ggplot(data = data_lm_all, aes(x = predict, y = residuos)) +
  geom_point(aes(color = residuos)) +
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") +
  geom_hline(yintercept = 0) +
  geom_segment(aes(xend = predict, yend = 0), alpha = 0.2) +
  labs(title = "Distribución de los residuos", x = "predicción modelo",
       y = "residuo") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")
```

Vamos a obtener más información de los residuos:
```{r, fig.align='center'}
summary(lm_fit_ultimo_all$residuals)
```
Los residuos se distribuyen de forma aleatoria entorno al 0 por lo que se acepta la linealidad.
El error tiene una relación lineal con la variable objetivo, sería mejorable quizá incorporando nuevos predictores. El rango de valores que toman los residuos es amplio, respecto a su valor medio de cero.

Vamos a utilizar el diagrama de caja y bigotes para distinguir los outliers. Seguiremos el criterio de que un punto pertenece a los outliers si se separa de la caja más de 1.5 veces el rango intercuartílico, definido como RIC = Q3-Q1.
```{r, fig.align='center'}
outliers <- boxplot(lm_fit_ultimo_all$residuals)$out
```

Este sería el listado de outliers:
```{r}
outliers
```


```{r, fig.align='center'}
par(mfrow = c(2,2))
plot(lm_fit_ultimo_all)
```
- Primer gráfico: muestra los residuos por cada predición. Si hay una distribución lineal de los residuos, entonces podemos pensar que el modelo se ajusta bien. Si se observa cualquier tipo de distribución no lineal ni constante, podemos sospechar que el modelo no se ajusta del todo.
- Segundo gráfico: tipo Normal Q-Q. Compara los residuos estandarizados con la distribución teorica Normal. Si los puntos se alejan de la linea normal, indica que los residuos no se ajustan a una distribución Normal.
- Tercer gráfico: Scale-Location o también llamado Spread-Location, muestra si los residuos se distribuyen por igual a lo largo de los rangos de predictores. Permite verificar si la varianza es igual (homocedasticidad). Si se ve una línea horizontal con puntos de dispersión iguales (al azar), es una buena señal.
- Cuarto gráfico: Residuals vs Leverage. Nos ayuda a encontrar casos influyentes. No todos los valores atípicos influyen en el análisis de regresión lineal. Aunque parezcan valores extremos por salirse de lo habitual, igual no influyen en el modelo. De igual forma, valores que aparentemente confirman el modelo, podrían ser muy influyentes y alterar los resultados si los excluimos del análisis. Hay que observar valores periféricos en la esquina superior derecha o en la esquina inferior derecha. Esos lugares son los lugares donde los casos pueden influir en una línea de regresión. Hay que buscar casos fuera de la línea, la distancia de Cook. Los resultados de la regresión se alterarán si excluimos esos casos.

Guardamos el modelo para usarlo posteriormente con los valores de test:
```{r, fig.align='center'}
saveRDS(lm_fit_ultimo_all, "./models/lm_fit_ultimo_deuda_publica+ipc+tasa_paro+pib.rds")
```

Cargamos el modelo guardado para usarlo con los modelos de test:
```{r, fig.align='center'}
save_lm_fit_ultimo_all <- readRDS("./models/lm_fit_ultimo_deuda_publica+ipc+tasa_paro+pib.rds")
print(save_lm_fit_ultimo_all)
```

Vamos a calcular el test MSE (mean squared error) de los datos de validación:
```{r}
predict_lm_fit_ultimo_all.ultimo <- predict(save_lm_fit_ultimo_all, data_test)
#length(predict_lm_fit_ultimo_all.ultimo)
#length(data_test$ultimo)
# names(save_lm_fit_ultimo_all)

#MSE
mse_test_predict_lm_fit_ultimo_all <- mean((data_test$ultimo - predict_lm_fit_ultimo_all.ultimo)^2)
mse_test_predict_lm_fit_ultimo_all
```
Este valor "5729902" es algo mejor que el obtenido en los datos de train "5786695".

Vamos a plotear los valores predichos por el modelo y ver tabla con resultados reales y predichos:
```{r}
plot(predict_lm_fit_ultimo_all.ultimo)

result_predict_lm_fit_ultimo_all.ultimo <- cbind(data_test, predict_lm_fit_ultimo_all.ultimo)
result_predict_lm_fit_ultimo_all.ultimo
```


```{r}
plot(predict_lm_fit_ultimo_all.ultimo, data_test$ultimo,
     xlab="predicted", ylab="actual")
abline(a=0, b=1)
```


Vamos a validar el modelo mediante 10 K-fold Cross Validation. Con este tipo de técnica vamos a evitar:
- La estimación del error de test puede variar dependiendo de las observaciones que caigan en el conjunto de training y cuáles en el de test
- En el cálculo anterior como sólo se ha utilizado un subconjunto de los datos disponibles para entrenar el modelo, el error de test estimado será, probablemente, una sobre-estimación del verdadero error de test del modelo.
```{r}
fold_index_list <- createFolds(data$ultimo, k =4)
#fold_index_list

mat <- matrix(nrow = 0, ncol = 4)
colnames(mat) <- c('mse_train_1', 'mse_test_1', 'mse_train_2', 'mse_test_2')
for(fold in fold_index_list){  
  training_data <- data[-fold, ]
  test_data <- data[fold, ]
  mod_1 <- lm(ultimo ~ deuda_publica + ipc + tasa_paro + pib, data = training_data)
  mod_2 <- lm(ultimo ~ deuda_publica + ipc + pib, data = training_data)
  mse_train_1 <- mean((mod_1$residuals)**2)
  mse_train_2 <- mean((mod_2$residuals)**2)
  mse_test_1 <- mean((test_data$ultimo - predict(mod_1, test_data))**2)
  mse_test_2 <- mean((test_data$ultimo - predict(mod_2, test_data))**2)
  mat <- rbind(mat, c(mse_train_1,
                      mse_test_1,
                      mse_train_2,
                      mse_test_2))
}
mat <- as.data.frame(mat)
colMeans(mat)

```

Otra forma de aplicar la técnica de remuestreo K-fold Cross Validation sobre los datos de train:
```{r}
set.seed(23) 
train.control <- trainControl(method = "cv", number = 10)
# Entre
kfold_training_model <- train(ultimo ~ deuda_publica + ipc + tasa_paro + pib, data = data_training, method = "lm",
               trControl = train.control)
# Summarize the results
print(kfold_training_model)
```